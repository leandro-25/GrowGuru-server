import os
import time
import threading
import concurrent.futures
from collections import deque
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional

from crewai import Agent, Task, Crew, Process
from crewai_tools import ScrapeWebsiteTool
import litellm
from litellm.exceptions import RateLimitError
from langchain_community.chat_models.litellm import ChatLiteLLM

# Configura√ß√µes
otimizacoes = {
    'max_workers': 5,  # N√∫mero de threads paralelas (ajuste conforme necess√°rio)
    'max_requests_per_minute': 25,  # Mant√©m abaixo do limite de 30 para seguran√ßa
    'retry_attempts': 10,  # N√∫mero de tentativas por ticker
    'base_delay': 10,  # Delay base entre requisi√ß√µes em segundos
}

# Configura√ß√£o da API
def setup_llm():
    os.environ["GROQ_API_KEY"] = "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"
    litellm.set_verbose = False
    return ChatLiteLLM(model="groq/gemma2-9b-it", temperature=0.7)

# Controle de taxa de requisi√ß√µes
class RateLimiter:
    def __init__(self, max_requests: int, time_window: int = 60):
        self.requests = deque()
        self.max_requests = max_requests
        self.time_window = time_window
        self.lock = threading.Lock()

    def wait_if_needed(self):
        with self.lock:
            now = time.time()
            # Remove registros mais antigos que a janela de tempo
            while self.requests and self.requests[0] <= now - self.time_window:
                self.requests.popleft()
            
            if len(self.requests) >= self.max_requests:
                sleep_time = (self.requests[0] + self.time_window) - now
                if sleep_time > 0:
                    time.sleep(sleep_time)
            
            self.requests.append(time.time())

# Processa um √∫nico ticker com tratamento de erros
def process_ticker(ticker: str, rate_limiter: RateLimiter, llm: ChatLiteLLM, retry_count: int = 0) -> Optional[str]:
    if retry_count >= otimizacoes['retry_attempts']:
        print(f"‚ùå M√°ximo de tentativas atingido para {ticker}")
        return None
    
    try:
        rate_limiter.wait_if_needed()
        print(f"üîÑ Processando {ticker} (tentativa {retry_count + 1}/{otimizacoes['retry_attempts']})")
        
        # Cria o agente e a tarefa
        news_scraper_tool = ScrapeWebsiteTool(
            website_url=f"https://news.google.com/search?q={ticker}&tbs=qdr:m"
        )
        
        news_agent = Agent(
            role="Analista de Not√≠cias Financeiras S√™nior",
            goal="Encontrar e resumir not√≠cias relevantes sobre ativos de mercado",
            backstory=("Voc√™ √© um analista financeiro experiente, especializado em coletar "
                     "not√≠cias recentes e identificar o sentimento do mercado."),
            tools=[news_scraper_tool],
            llm=llm,
            verbose=False,
            allow_delegation=False
        )
        
        # Definindo a descri√ß√£o detalhada
        task_description = (
            f"Analise as 5 not√≠cias mais recentes sobre o ativo {ticker} e gere um relat√≥rio detalhado. "
            "Selecione apenas as 5 not√≠cias mais relevantes e para cada uma inclua: t√≠tulo, resumo e impacto potencial. "
            "No final, forne√ßa um resumo geral e um impacto consolidado. "
            "IMPORTANTE: Limite a an√°lise a no m√°ximo 5 not√≠cias por ativo."
        )
        
        # Definindo o formato esperado da sa√≠da
        expected_output = (
            f"**An√°lise de Not√≠cias para {ticker}**\n\n"
            "**Not√≠cia 1:**\n"
            "- **T√≠tulo:** [T√≠tulo da not√≠cia]\n"
            "- **Resumo:** [Resumo de at√© 2 linhas]\n"
            "- **Impacto Potencial:** [Muito Baixo/Baixo/Neutro/Alto/Muito Alto]\n\n"
            "**Resumo Geral:**\n"
            "[Resumo consolidado do cen√°rio atual do ativo]\n\n"
            "**Impacto Geral Consolidado:** [Muito Baixo/Baixo/Neutro/Alto/Muito Alto]"
        )
        
        # Criando a tarefa
        news_task = Task(
            description=task_description,
            expected_output=expected_output,
            tools=[news_scraper_tool],
            agent=news_agent
        )
        
        crew = Crew(
            agents=[news_agent],
            tasks=[news_task],
            process=Process.sequential,
            verbose=False
        )
        
        return crew.kickoff()
        
    except RateLimitError as e:
        wait_time = (retry_count + 1) * 15  # Aumenta o tempo de espera a cada tentativa
        print(f"‚ö†Ô∏è RateLimitError em {ticker}. Tentando novamente em {wait_time} segundos...")
        time.sleep(wait_time)
        return process_ticker(ticker, rate_limiter, llm, retry_count + 1)
        
    except Exception as e:
        print(f"‚ùå Erro ao processar {ticker}: {str(e)}")
        return None

def main():
    # Lista de tickers (mantive apenas alguns para teste)
    tickers_to_process = [
        "AALR3.SA", "ABCB4.SA", "ABEV3.SA", "B3SA3.SA", "BBAS3.SA",
        "BBDC4.SA", "ITUB4.SA", "PETR4.SA", "VALE3.SA", "WEGE3.SA"
    ]
    
    print(f"üöÄ Iniciando processamento de {len(tickers_to_process)} tickers")
    print(f"‚öôÔ∏è  Configura√ß√µes: {otimizacoes}")
    
    llm = setup_llm()
    rate_limiter = RateLimiter(max_requests=otimizacoes['max_requests_per_minute'])
    results = {}
    
    start_time = time.time()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=otimizacoes['max_workers']) as executor:
        future_to_ticker = {
            executor.submit(process_ticker, ticker, rate_limiter, llm): ticker 
            for ticker in tickers_to_process
        }
        
        for future in concurrent.futures.as_completed(future_to_ticker):
            ticker = future_to_ticker[future]
            try:
                result = future.result()
                if result:
                    # Converte o resultado para string se for um objeto CrewOutput
                    result_str = str(result)
                    results[ticker] = result_str
                    print(f"‚úÖ {ticker} processado com sucesso!")
                else:
                    print(f"‚ö†Ô∏è  {ticker} n√£o retornou resultados")
            except Exception as e:
                print(f"‚ùå Erro ao processar {ticker}: {str(e)}")
    
    # Exibe estat√≠sticas
    elapsed = time.time() - start_time
    print(f"\nüèÅ Processamento conclu√≠do em {elapsed:.2f} segundos")
    print(f"üìä {len(results)} de {len(tickers_to_process)} tickers processados com sucesso")
    
    with open('resultados_analise.txt', 'w', encoding='utf-8') as f:
        for ticker, result in results.items():
            f.write(f"\n{'='*50}\n")
            f.write(f"üìà AN√ÅLISE PARA {ticker}\n")
            f.write(f"{'='*50}\n\n")
            # Garante que o resultado seja tratado como string
            result_str = str(result).strip()
            # Adiciona formata√ß√£o consistente se necess√°rio
            if not result_str.startswith("**An√°lise de Not√≠cias para"):
                f.write(f"**An√°lise de Not√≠cias para {ticker}**\n\n")
            f.write(f"{result_str}\n\n")
    
    print("\nüìù Resultados salvos em 'resultados_analise.txt'")

if __name__ == "__main__":
    main()

# ğŸ“¦ Instalar dependÃªncias
# pip install -q crewai crewai_tools litellm beautifulsoup4 requests langchain-community

# ğŸŒ Imports
import os
import time # Importar o mÃ³dulo time para usar sleep
from crewai import Agent, Task, Crew, Process
from crewai_tools import ScrapeWebsiteTool
import litellm

# Importar a integraÃ§Ã£o oficial do Litellm para LangChain/CrewAI
from langchain_community.chat_models.litellm import ChatLiteLLM


# ğŸ§  Definir API key da Groq
os.environ["GROQ_API_KEY"] = "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"

# ğŸ”§ Configurar Litellm
litellm.set_verbose = False

# âœ… CORREÃ‡ÃƒO: Usar a classe oficial ChatLiteLLM em vez de uma personalizada.
# Isso garante compatibilidade total com todos os recursos do CrewAI.
llm = ChatLiteLLM(
    model="groq/gemma2-9b-it",
    temperature=0.7
)

# ğŸ†• Lista de tickers para processar
# Coloquei 4 exemplos, vocÃª pode ajustar conforme necessÃ¡rio
tickers_to_process = ["PETR4", "VALE3", "ITUB4", "BBDC4"]

# ğŸ”„ Loop atravÃ©s de cada ticker na lista
for i, current_ticker in enumerate(tickers_to_process):
    print(f"\n{'='*50}")
    print(f"ğŸš€ Processando ticker: {current_ticker} ({i+1}/{len(tickers_to_process)})")
    print(f"{'='*50}\n")

    # ğŸ› ï¸ Tool com base no ticker ATUAL
    # A ferramenta precisa ser recriada para cada ticker para apontar para a URL correta
    news_scraper_tool = ScrapeWebsiteTool(
        website_url=f"https://news.google.com/search?q={current_ticker}"
    )

    # ğŸ‘¤ Agente
    # O agente tambÃ©m Ã© recriado para garantir que use a ferramenta atualizada
    news_agent = Agent(
        role="Analista de NotÃ­cias Financeiras",
        goal="Encontrar e resumir notÃ­cias relevantes sobre ativos de mercado",
        backstory=(
            "VocÃª Ã© um analista financeiro especializado em coletar notÃ­cias recentes "
            "e identificar possÃ­veis impactos no mercado para orientar investidores."
        ),
        tools=[news_scraper_tool], # Passa a ferramenta ATUALIZADA
        llm=llm,
        verbose=True,
        allow_delegation=False
    )

    # ğŸ§¾ Task
    # A tarefa Ã© recriada para incluir o ticker atualizado na descriÃ§Ã£o
    news_task = Task(
        description=(
            f"VocÃª deve buscar as notÃ­cias mais recentes relacionadas ao ativo {current_ticker}. "
            "Analise o conteÃºdo da pÃ¡gina fornecida pela ferramenta e gere um relatÃ³rio "
            "com os seguintes pontos:\n\n"
            "1. TÃ­tulos das principais notÃ­cias\n"
            "2. Resumo de atÃ© 2 linhas de cada notÃ­cia\n"
            "3. Qualquer sentimento ou impacto potencial detectado\n\n"
            "Seu relatÃ³rio deve ser bem formatado e informativo para um investidor que quer entender o contexto atual do ativo."
        ),
        expected_output=f"Um relatÃ³rio formatado com tÃ­tulos, resumos e insights sobre o ativo {current_ticker}.",
        tools=[news_scraper_tool], # Passa a ferramenta ATUALIZADA
        agent=news_agent # Passa o agente ATUALIZADO
    )

    # ğŸ‘¥ Crew
    # O Crew Ã© recriado para usar o agente e a tarefa atuais
    crew = Crew(
        agents=[news_agent],
        tasks=[news_task],
        process=Process.sequential,
        verbose=True
    )

    # ğŸ Executar
    result = crew.kickoff()
    print(f"\nâœ… RESULTADO FINAL PARA {current_ticker}:\n")
    print(result)

    # â° Intervalo de 70 segundos entre as chamadas da API (se nÃ£o for o Ãºltimo ticker)
    if i < len(tickers_to_process) - 1:
        print(f"\nğŸš§ Aguardando 70 segundos antes de processar o prÃ³ximo ticker...")
        time.sleep(70)

print("\nğŸš€ Todos os tickers foram processados!")